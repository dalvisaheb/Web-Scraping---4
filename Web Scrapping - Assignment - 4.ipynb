{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dbb069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0abb46be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a GET request to the URL\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0494ccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find('table', class_='wikitable')\n",
    "rows = table.find_all('tr')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7b2ea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for row in rows:\n",
    "    cells = row.find_all('td')\n",
    "    if len(cells) >= 5:  # Check if there are enough cells\n",
    "        rank = safe_get_text(cells[0])\n",
    "        name = safe_get_text(cells[1])\n",
    "        artist = safe_get_text(cells[2])\n",
    "        upload_date = safe_get_text(cells[4])\n",
    "        views = safe_get_text(cells[3])\n",
    "\n",
    "    data.append({\n",
    "        'Rank': rank,\n",
    "        'Name': name,\n",
    "        'Artist': artist,\n",
    "        'Upload Date': upload_date,\n",
    "        'Views': views})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0df6e7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 row\n",
      "0  [\\n, [1.], \\n, [\", [Baby Shark Dance], \", [<a ...\n",
      "1  [\\n, [2.], \\n, [\", [Despacito], \", [<a href=\"#...\n",
      "2  [\\n, [3.], \\n, [\", [Johny Johny Yes Papa], \", ...\n",
      "3  [\\n, [4.], \\n, [\"Bath Song\", [<a href=\"#cite_n...\n",
      "4  [\\n, [5.], \\n, [\", [Shape of You], \", [<a href...\n",
      "5  [\\n, [6.], \\n, [\", [See You Again], \", [<a hre...\n",
      "6  [\\n, [7.], \\n, [\"Phonics Song with Two Words\",...\n",
      "7  [\\n, [8.], \\n, [\", [Wheels on the Bus], \", [<a...\n",
      "8  [\\n, [9.], \\n, [\", [Uptown Funk], \", [<a href=...\n",
      "9  [\\n, [10.], \\n, [\"Learning Colors – Colorful E...\n"
     ]
    }
   ],
   "source": [
    "# Create a Pandas DataFrame from the headers\n",
    "df = pd.DataFrame({'row': rows})\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45329a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question no 2\n",
    "#Scrape the details teamIndia’sinternationalfixtures from bcci.tv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5f0994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dca1d863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a GET request to the URL\n",
    "url = 'https://www.bcci.tv/'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b3ea4d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find link to international fixtures page\n",
    "fixtures_link = soup.find('a', text='International Fixtures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "28607a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = soup.find_all('div', class_='js-list')\n",
    "data = []\n",
    "for match in matches:\n",
    "    title = safe_get_text(match.find('strong'))\n",
    "    series = safe_get_text(match.find('span', class_='fixture__format'))\n",
    "    place = safe_get_text(match.find('p', class_='fixture__additional-info'))\n",
    "    date = safe_get_text(match.find('span', class_='fixture__date'))\n",
    "    time = safe_get_text(match.find('span', class_='fixture__time'))\n",
    "\n",
    "    data.append({\n",
    "        'Match Title': title,\n",
    "        'Series': series,\n",
    "        'Place': place,\n",
    "         'Date': date,\n",
    "         'Time': time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1b6ad7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Match Title, Series, Place, Date, Time]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Create a Pandas DataFrame from the headers\n",
    "# create a data frame from the extracted data\n",
    "df = pd.DataFrame(data, columns=[\"Match Title\", \"Series\", \"Place\",\"Date\",\"Time\"])\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2e5c954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4 -Scrape the details of State-wise GDP ofIndia fromstatisticstime.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b329be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f4d0f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a3535e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find(\"table\", class_=\"wikitable\")\n",
    "rows = table.find_all(\"tr\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "443ffab6",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8204\\2761413814.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"td\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mrank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0martist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for row in rows:\n",
    "    columns = row.find_all(\"td\")\n",
    "    rank = columns[0].text.strip()\n",
    "    name = columns[1].text.strip()\n",
    "    artist = columns[2].text.strip()\n",
    "    upload_date = columns[4].text.strip()\n",
    "    views = columns[3].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28a7125f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 30.\n",
      "Name: \"Lean On\"[53]\n",
      "Artist: Major Lazer\n",
      "Upload Date: March 22, 2015\n",
      "Views: 3.40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Rank:\", rank)\n",
    "print(\"Name:\", name)\n",
    "print(\"Artist:\", artist)\n",
    "print(\"Upload Date:\", upload_date)\n",
    "print(\"Views:\", views)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b37da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5 - Scrape the details of top 100 songs on billiboard.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c22e7502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6977a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get the Billboard Hot 100 page URL\n",
    "base_url = \"https://www.billboard.com\"\n",
    "charts_url = base_url + \"/charts\"\n",
    "hot100_url = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79d222e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Navigate to the Hot 100 page\n",
    "response = requests.get(charts_url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9713197",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8204\\1320416604.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Find the Hot 100 page link\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcharts_section\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"section\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"charts-section\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcharts_links\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcharts_section\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"a\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"charts-section__link\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "# Find the Hot 100 page link\n",
    "charts_section = soup.find(\"section\", class_=\"charts-section\")\n",
    "charts_links = charts_section.find_all(\"a\", class_=\"charts-section__link\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4e771c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'charts_links' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8204\\4149861466.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcharts_links\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m\"hot-100\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlink\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"href\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mhot100_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_url\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlink\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"href\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'charts_links' is not defined"
     ]
    }
   ],
   "source": [
    "for link in charts_links:\n",
    "    if \"hot-100\" in link[\"href\"]:\n",
    "        hot100_url = base_url + link[\"href\"]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b67d220e",
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingSchema",
     "evalue": "Invalid URL '': No scheme supplied. Perhaps you meant http://?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8204\\4133198537.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Step 3: Scrape the details from the Hot 100 page\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhot100_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"html.parser\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \"\"\"\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"get\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    571\u001b[0m             \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m         )\n\u001b[1;32m--> 573\u001b[1;33m         \u001b[0mprep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         \u001b[0mproxies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproxies\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mprepare_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPreparedRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 484\u001b[1;33m         p.prepare(\n\u001b[0m\u001b[0;32m    485\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m             \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mprepare\u001b[1;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_headers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_cookies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcookies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mprepare_url\u001b[1;34m(self, url, params)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mscheme\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m             raise MissingSchema(\n\u001b[0m\u001b[0;32m    440\u001b[0m                 \u001b[1;34mf\"Invalid URL {url!r}: No scheme supplied. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[1;34mf\"Perhaps you meant http://{url}?\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMissingSchema\u001b[0m: Invalid URL '': No scheme supplied. Perhaps you meant http://?"
     ]
    }
   ],
   "source": [
    "# Step 3: Scrape the details from the Hot 100 page\n",
    "response = requests.get(hot100_url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57713a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find(\"table\", class_=\"chart-list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fd5f862",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8204\\4263933253.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Step 4: Extract the details for each song\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"li\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"chart-list__element\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "# Step 4: Extract the details for each song\n",
    "rows = table.find_all(\"li\", class_=\"chart-list__element\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a5383ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8204\\1985782742.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0msong_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"span\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"chart-element__information__song\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0martist_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"span\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"chart-element__information__artist\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mlast_week_rank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"span\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"chart-element__meta\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpeak_rank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"span\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"chart-element__meta-text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "for row in rows:\n",
    "    song_name = row.find(\"span\", class_=\"chart-element__information__song\").text.strip()\n",
    "    artist_name = row.find(\"span\", class_=\"chart-element__information__artist\").text.strip()\n",
    "    last_week_rank = row.find(\"span\", class_=\"chart-element__meta\").text.strip()\n",
    "    peak_rank = row.find(\"span\", class_=\"chart-element__meta-text\").text.strip()\n",
    "    weeks_on_board = row.find_all(\"span\", class_=\"chart-element__meta-text\")[-1].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "989d2924",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'song_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8204\\1606047277.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Song Name:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msong_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Artist Name:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0martist_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Last Week Rank:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_week_rank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Peak Rank:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpeak_rank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Weeks on Board:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweeks_on_board\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'song_name' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Song Name:\", song_name)\n",
    "print(\"Artist Name:\", artist_name)\n",
    "print(\"Last Week Rank:\", last_week_rank)\n",
    "print(\"Peak Rank:\", peak_rank)\n",
    "print(\"Weeks on Board:\", weeks_on_board)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5867669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 6 - Scrape the details of Highest sellingnovels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d14ed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fbd5fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56bad003",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find(\"table\")\n",
    "rows = table.find_all(\"tr\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50758977",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in rows:\n",
    "    columns = row.find_all(\"td\")\n",
    "    if len(columns) >= 5:\n",
    "        book_name = columns[1].text.strip()\n",
    "        author_name = columns[2].text.strip()\n",
    "        volumes_sold = columns[3].text.strip()\n",
    "        publisher = columns[4].text.strip()\n",
    "        genre = columns[5].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b256641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book Name: Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours\n",
      "Author Name: Oliver, Jamie\n",
      "Volumes Sold: 791,095\n",
      "Publisher: Penguin\n",
      "Genre: Food & Drink: General\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Book Name:\", book_name)\n",
    "print(\"Author Name:\", author_name)\n",
    "print(\"Volumes Sold:\", volumes_sold)\n",
    "print(\"Publisher:\", publisher)\n",
    "print(\"Genre:\", genre)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63f04239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 7 - Scrape the details most watched tv series of all time from imdb.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32fc058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cd17a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.imdb.com/list/ls095964455/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "314ba94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_list = soup.find_all(\"div\", class_=\"lister-item-content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "927b5e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for series in series_list:\n",
    "    name = series.find(\"h3\", class_=\"lister-item-header\").a.text.strip()\n",
    "    year_span = series.find(\"span\", class_=\"lister-item-year\").text.strip(\"()\")\n",
    "    genre = series.find(\"span\", class_=\"genre\").text.strip()\n",
    "    run_time = series.find(\"span\", class_=\"runtime\").text.strip()\n",
    "    ratings = series.find(\"div\", class_=\"ipl-rating-star small\").span.text.strip()\n",
    "    votes = series.find(\"span\", attrs={\"name\": \"nv\"})[\"data-value\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d641b775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: The Haunting of Hill House\n",
      "Year Span: 2018\n",
      "Genre: Drama, Horror, Mystery\n",
      "Run Time: 572 min\n",
      "Ratings: \n",
      "Votes: 261322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Name:\", name)\n",
    "print(\"Year Span:\", year_span)\n",
    "print(\"Genre:\", genre)\n",
    "print(\"Run Time:\", run_time)\n",
    "print(\"Ratings:\", ratings)\n",
    "print(\"Votes:\", votes)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43be0676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 8 - Details of Datasetsfrom UCI machine learning repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98ace588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be581fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de303f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and follow the link to the Show All Dataset page\n",
    "links = soup.find_all(\"a\")\n",
    "show_all_url = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "11fab0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in links:\n",
    "    if \"Show All Data Sets\" in link.text:\n",
    "        show_all_url = urljoin(url, link.get(\"href\", \"\"))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "92d7603d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve the Show All Dataset URL.\n"
     ]
    }
   ],
   "source": [
    "if not show_all_url:\n",
    "    print(\"Failed to retrieve the Show All Dataset URL.\")\n",
    "else:\n",
    "    # Visit the Show All Dataset page\n",
    "    response = requests.get(show_all_url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6cff23d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the table containing the dataset details\n",
    "table = soup.find(\"table\", class_=\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c4daea17",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8204\\4147624890.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Find the table containing the dataset details\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"table\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"table-bordered\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Exclude the header row\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    " # Find the table containing the dataset details\n",
    "table = soup.find(\"table\", class_=\"table-bordered\")\n",
    "rows = table.find_all(\"tr\")[1:]  # Exclude the header row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bdb3f18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in rows:\n",
    "        columns = row.find_all(\"td\")\n",
    "        if len(columns) >= 6:\n",
    "            dataset_name = columns[0].text.strip()\n",
    "            task = columns[1].text.strip()\n",
    "            attribute_type = columns[2].text.strip()\n",
    "            instances = columns[3].text.strip()\n",
    "            attributes = columns[4].text.strip()\n",
    "            year = columns[5].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dcfbdd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name: 100\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data_type' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8204\\3754617357.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Dataset Name:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data Type:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Task:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Attribute Type:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattribute_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of Instances:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_type' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Name:\", dataset_name)\n",
    "print(\"Data Type:\", data_type)\n",
    "print(\"Task:\", task)\n",
    "print(\"Attribute Type:\", attribute_type)\n",
    "print(\"Number of Instances:\", instances)\n",
    "print(\"Number of Attributes:\", attributes)\n",
    "print(\"Year:\", year)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bdd2f37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 9 - Scrape the details of Data science recruiters Url = https://www.naukri.com/hr-recruiters-consultant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "93d4ae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "88f02b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.naukri.com/hr-recruiters-consultant\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f8837bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "recruiter_list = soup.find_all(\"div\", class_=\"recInfo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "db7832ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for recruiter in recruiter_list:\n",
    "    name_element = recruiter.find(\"span\", class_=\"fl\")\n",
    "    name = name_element.text.strip() if name_element else \"N/A\"\n",
    "    designation_element = recruiter.find(\"span\", class_=\"designation\")\n",
    "    designation = designation_element.text.strip() if designation_element else \"N/A\"\n",
    "    company_element = recruiter.find(\"p\", class_=\"highlightable\")\n",
    "    company = company_element.text.strip() if company_element else \"N/A\"\n",
    "    skills_element = recruiter.find(\"div\", class_=\"hireSec\")\n",
    "    skills = skills_element.text.strip() if skills_element else \"N/A\"\n",
    "    location_element = recruiter.find(\"small\", class_=\"ellipsis\")\n",
    "    location = location_element.text.strip() if location_element else \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c3e815af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: The Haunting of Hill House\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'designation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8204\\2136893532.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Name:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Designation:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesignation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Company:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompany\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Skills they hire for:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskills\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Location:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'designation' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Name:\", name)\n",
    "print(\"Designation:\", designation)\n",
    "print(\"Company:\", company)\n",
    "print(\"Skills they hire for:\", skills)\n",
    "print(\"Location:\", location)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209bf938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
